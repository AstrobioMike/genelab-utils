#!/usr/bin/env python

"""
This is a program for generating a README.txt file for GeneLab processed datasets.
"""

import os
import sys
import argparse
import textwrap
import zipfile
import re


parser = argparse.ArgumentParser(description = "This program generates the corresponding README file for GeneLab processed datasets, \
                                             currently designed to work with metagenomics and amplicon datasets. It is intended to \
                                             only be run after `GL-validate-processed-data` has been run successfully.")

required = parser.add_argument_group('required arguments')

required.add_argument("-a", "--assay", choices = ['Amplicon', 'Metagenomics', 'MethylSeq'], 
                      help = "Specifies which datatype (assay) this is for", action = "store", required = True)

required.add_argument("-g", "--GLDS-ID", help = 'GLDS ID (e.g. "GLDS-69")', action = "store", required = True)
parser.add_argument("--output", help = 'Name of output file (default: "README.txt", with appended prefix if one is provided)', default = "README.txt")
parser.add_argument("-p", "--output-prefix", help = "Output additional file prefix if there is one", action = "store", default = "")
parser.add_argument("--name", help = 'Name of individual who performed the processing (default: "Michael D. Lee")', default = "Michael D. Lee")
parser.add_argument("--email", help = 'Email address of individual who performed the processing (default: "Mike.Lee@nasa.gov")', default = "Mike.Lee@nasa.gov")
parser.add_argument("--protocol-ID", help = 'Protocol document ID followed (default: assay dependent)', default = "")
parser.add_argument("--primers-already-trimmed", help = "Add this flag if primers were trimmed prior to GeneLab processing, \
                    therefore there are no trimmed sequence data (only relevant for Amplicon)", action = "store_true")
parser.add_argument("--raw-reads-dir", help = "Specify location of raw reads directory if they are to be included", action = "store", default = "")


if len(sys.argv)==1:
    parser.print_help(sys.stderr)
    sys.exit(0)

args = parser.parse_args()

latest_amplicon_DPPD = "GL-DPPD-7104-A"
latest_metagenomics_DPPD = "GL-DPPD-7107"
latest_methylseq_DPPD = "GL-DPPD-7113"

################################################################################

def main():

    if args.assay == "Amplicon":

        processing_zip_contents = get_processing_zip_contents()

        with open(output_file, "w") as output:

            write_header(output, args.GLDS_ID, args.name, args.email, args.protocol_ID)

            write_amplicon_body(output, processing_zip_contents)


    elif args.assay == "Metagenomics":

        with open(output_file, "w") as output:

            write_header(output, args.GLDS_ID, args.name, args.email, args.protocol_ID)

            write_metagenomics_body(output)


    elif args.assay == "MethylSeq":

        with open(output_file, "w") as output:

            write_header(output, args.GLDS_ID, args.name, args.email, args.protocol_ID)

            write_methylseq_body(output)


################################################################################

# setting some colors
tty_colors = {
    'green' : '\033[0;32m%s\033[0m',
    'yellow' : '\033[0;33m%s\033[0m',
    'red' : '\033[0;31m%s\033[0m'
}


### functions ###
def color_text(text, color='green'):
    if sys.stdout.isatty():
        return tty_colors[color] % text
    else:
        return text


def wprint(text):
    """ print wrapper """

    print(textwrap.fill(text, width=80, initial_indent="  ", 
          subsequent_indent="  ", break_on_hyphens=False))


def report_failure(message, color = "yellow"):
    print("")
    wprint(color_text(message, color))
    print("\nREADME-generation failed.\n")

    sys.exit(1)


def check_for_file_and_contents(file_path):
    """ used by get_processing_zip_contents function """

    if not os.path.exists(file_path):
        report_failure("The expected file '" + str(file_path) + "' does not exist.")
    if not os.path.getsize(file_path) > 0:
        report_failure("The file '" + str(file_path) + "' is empty.")


def get_processing_zip_contents():
    """ this gets the filenames that are in the processing_info.zip to add them to the readme """

    check_for_file_and_contents(processing_zip_file)

    with zipfile.ZipFile(processing_zip_file) as zip_obj:

        entries = zip_obj.namelist()
        entries.sort()

    return(entries)


def write_header(output, GLDS_ID, name, email, protocol_ID):

    header = ["################################################################################\n",
              "{:<77} {:>0}".format("## This directory holds processed data for NASA " + str(GLDS_ID), "##\n"),
              "{:<77} {:>0}".format("## https://genelab-data.ndc.nasa.gov/genelab/accession/" + str(GLDS_ID) + "/", "##\n"),
              "{:<77} {:>0}".format("##", "##\n"),
              "{:<77} {:>0}".format("## Processed by " + str(name) + " (" + str(email) + ")", "##\n"),
              "{:<77} {:>0}".format("## Based on " + str(protocol_ID),  "##\n"),
              "################################################################################\n\n",
              "Summary of contents:\n\n"]

    output.writelines(header)


def write_amplicon_body(output, processing_zip_contents):

    # this file
    output.write("    {:<41} {:>0}".format("- " + str(output_file), "- this file\n\n"))

    # fastqc info
    output.write("    {:<41} {:>0}".format("- " + str(fastqc_dir), "- multiQC summary reports of FastQC runs\n\n"))

    # raw reads
    if args.raw_reads_dir != "":
        output.write("    {:<41} {:>0}".format("- " + str(args.raw_reads_dir), "- initial read fastq files\n\n"))

    # primer-trimmed reads if there are any
    if not args.primers_already_trimmed:
        output.write("    {:<41} {:>0}".format("- " + str(trimmed_reads_dir), "- primer-trimmed fastq files\n\n"))

    # quality-filtered reads
    output.write("    {:<41} {:>0}".format("- " + str(filtered_reads_dir), "- quality-filtered fastq files\n\n"))

    # outputs
    output.write("    {:<41} {:>0}".format("- " + str(final_outputs_dir), "- primary output files (may or may not have additional prefix)\n"))
    output.write("        {:<37} {:>0}".format("- *.fasta", "- fasta file of recovered sequences\n"))
    output.write("        {:<37} {:>0}".format("- *counts.tsv", "- count table of sequences across samples\n"))
    output.write("        {:<37} {:>0}".format("- *taxonomy.tsv", "- assigned taxonomy of recovered sequences\n"))
    output.write("        {:<37} {:>0}".format("- *taxonomy-and-count.tsv", "- combined table of counts and taxonomy\n"))
    output.write("        {:<37} {:>0}".format("- *taxonomy-and-count.biom.zip", "- biom-formatted output of counts and taxonomy\n"))
    output.write("        {:<37} {:>0}".format("- *read-count-tracking.tsv", "- read counts at each processing step\n\n"))

    # processing info
    output.write("    {:<41} {:>0}".format("- " + str(processing_zip_file), "- zip archive holding info related to processing\n"))
    for item in processing_zip_contents:

        num_levels = item.count("/")

        if num_levels > 1 and not item.endswith("/"):
            out_item = re.sub(r'^.*/', '', str(item))
        elif num_levels == 1 and not item.endswith("/"):
            out_item = re.sub(r'^.*/', '', str(item))
        elif num_levels > 1:
            out_item = re.sub(r'^[^/]*/', '', str(item))
        else:
            out_item = str(item)

        if item.endswith('/'):
            num_levels -= 1

        num_spaces = num_levels * 4

        output.write("        " + " " * num_spaces + "- " + out_item + "\n")

    output.write("\n")


def write_metagenomics_body(output):

    # this file
    output.write("    {:<75} {:>0}".format("- " + str(output_file), "- this file\n\n"))

    # fastqc info
    output.write("    {:<75} {:>0}".format("- " + str(fastqc_dir), "- multiQC summary reports of FastQC runs\n\n"))

    # raw reads
    if args.raw_reads_dir != "":
        output.write("    {:<75} {:>0}".format("- " + str(args.raw_reads_dir), "- initial read fastq files\n\n"))

    # quality-filtered reads
    output.write("    {:<75} {:>0}".format("- " + str(filtered_reads_dir), "- quality-filtered fastq files\n\n"))

    # outputs
    output.write("    {:<75} {:>0}".format("- " + str(assembly_based_dir), "- results generated from assembly-based approach\n\n"))

    output.write("        {:<71} {:>0}".format(f"- {output_prefix}Assembly-based-processing-overview_{assay_suffix}.tsv", "- Assembly-based overview per sample\n\n"))
    
    output.write("        {:<71} {:>0}".format("- " + str(assemblies_dir), "- per-sample assembly files and info\n"))
    output.write("            {:<67} {:>0}".format("- *-assembly.fasta", "- fasta files of individual sample assemblies\n"))
    output.write("            {:<67} {:>0}".format(f"- {output_prefix}assembly-summaries_{assay_suffix}.tsv", "- table of all assemblies' summary statistics\n"))
    output.write("            {:<67} {:>0}".format(f"- {output_prefix}Failed-assemblies_{assay_suffix}.tsv", "- samples that didn't assemble any contigs (if any)\n\n"))

    output.write("        {:<71} {:>0}".format("- " + str(genes_dir), "- per-sample predicted gene files\n"))
    output.write("            {:<67} {:>0}".format("- *.faa", "- gene amino-acid sequences\n"))
    output.write("            {:<67} {:>0}".format("- *.fasta", "- gene nucleotide sequences\n"))
    output.write("            {:<67} {:>0}".format("- *.gff", "- predicted genes in general feature format\n\n"))

    output.write("        {:<71} {:>0}".format("- " + str(annotations_and_tax_dir), "- per-sample Kegg Orthology (KO) annotations, taxonomy, and coverages\n"))
    output.write("            {:<67} {:>0}".format("- *-gene-coverage-annotation-tax.tsv", "- tables with gene coverage, annotation, and taxonomy info\n"))
    output.write("            {:<67} {:>0}".format("- *-contig-coverage-and-tax.tsv", "- tables with contig coverage and taxonomy info\n\n"))

    output.write("        {:<71} {:>0}".format("- " + str(mapping_dir), "- per-sample bam, coverage, and mapping info files\n"))
    output.write("            {:<67} {:>0}".format("- *.bam", "- bam files\n"))
    output.write("            {:<67} {:>0}".format("- *.tsv", "- coverage files used for metabat2 binning\n"))
    output.write("            {:<67} {:>0}".format("- *.txt", "- stdout from bowtie2 mapping\n\n"))

    if os.path.exists(assembly_based_dir + bins_dir):
        output.write("        {:<71} {:>0}".format("- " + str(bins_dir), "- genomic bins recovered (if any)\n"))
        output.write("            {:<67} {:>0}".format("- *.fasta", "- fasta files of bins recovered\n"))
        output.write("            {:<67} {:>0}".format(f"- {output_prefix}bins-overview_{assay_suffix}.tsv", "- summary stats of bins recovered\n\n"))

    if os.path.exists(assembly_based_dir + MAGs_dir):
        output.write("        {:<71} {:>0}".format("- " + str(MAGs_dir), "- high-quality Metagenome-Assembled Genomes recovered (if any; > 90% est. comp., < 10% est. redundancy)\n"))
        output.write("            {:<67} {:>0}".format("- *.fasta", "- fasta files of MAGs\n"))
        output.write("            {:<67} {:>0}".format(f"- {output_prefix}MAGs-overview_{assay_suffix}.tsv", "- summary stats of MAGs including GTDB taxonomy\n"))
        output.write("            {:<67} {:>0}".format(f"- {output_prefix}MAG-level-KO-annotations_{assay_suffix}.tsv", "- KO functional annotations associated with each MAG\n"))
        output.write("            {:<67} {:>0}".format(f"- {output_prefix}MAG-KEGG-Decoder*", "- KEGG-Decoder summaries of MAG functional annotations\n\n"))


    output.write("        {:<71} {:>0}".format("- " + str(combined_output_dir), "- summary outputs with all samples combined\n"))
    output.write("            {:<67} {:>0}".format(f"- {output_prefix}Combined-gene-level-KO-function-coverages_{assay_suffix}.tsv", "- table of combined KO function coverages\n"))
    output.write("            {:<67} {:>0}".format(f"- {output_prefix}Combined-gene-level-KO-function-coverages-CPM_{assay_suffix}.tsv", "- table of combined KO function coverages, normalized to coverage per million\n"))
    output.write("            {:<67} {:>0}".format(f"- {output_prefix}Combined-gene-level-taxonomy-coverages_{assay_suffix}.tsv", "- table of combined, gene-level taxonomy coverages\n"))
    output.write("            {:<67} {:>0}".format(f"- {output_prefix}Combined-gene-level-taxonomy-coverages-CPM_{assay_suffix}.tsv", "- table of combined, gene-level taxonomy coverages, normalized to coverage per million\n"))
    output.write("            {:<67} {:>0}".format(f"- {output_prefix}Combined-contig-level-taxonomy-coverages_{assay_suffix}.tsv", "- table of combined, contig-level taxonomy coverages\n"))
    output.write("            {:<67} {:>0}".format(f"- {output_prefix}Combined-contig-level-taxonomy-coverages-CPM_{assay_suffix}.tsv", "- table of combined, contig-level taxonomy coverages, normalized to coverage per million\n\n"))

    output.write("    {:<75} {:>0}".format("- " + str(read_based_dir), "- results generated from read-based approach\n"))
    output.write("        {:<71} {:>0}".format(f"- {output_prefix}Gene-families_{assay_suffix}.tsv", "- gene-family abundances\n"))
    output.write("        {:<71} {:>0}".format(f"- {output_prefix}Gene-families-grouped-by-taxa_{assay_suffix}.tsv", "- gene-family abundances grouped by taxa\n"))
    output.write("        {:<71} {:>0}".format(f"- {output_prefix}Gene-families-cpm_{assay_suffix}.tsv", "- gene-family abundances normalized to copies-per-million\n"))
    output.write("        {:<71} {:>0}".format(f"- {output_prefix}Gene-families-KO-cpm_{assay_suffix}.tsv", "- KO term abundances normalized to copies-per-million\n"))
    output.write("        {:<71} {:>0}".format(f"- {output_prefix}Pathway-abundances_{assay_suffix}.tsv", "- pathway abundances\n"))
    output.write("        {:<71} {:>0}".format(f"- {output_prefix}Pathway-abundances-grouped-by-taxa_{assay_suffix}.tsv", "- pathway abundances grouped by taxa\n"))
    output.write("        {:<71} {:>0}".format(f"- {output_prefix}Pathway-abundances-cpm_{assay_suffix}.tsv", "- pathway abundances normalized to copies-per-million\n"))
    output.write("        {:<71} {:>0}".format(f"- {output_prefix}Pathway-coverages_{assay_suffix}.tsv", "- pathway coverages\n"))
    output.write("        {:<71} {:>0}".format(f"- {output_prefix}Pathway-coverages-grouped-by-taxa_{assay_suffix}.tsv", "- pathway coverages grouped by taxa\n"))
    output.write("        {:<71} {:>0}".format(f"- {output_prefix}Metaphlan-taxonomy_{assay_suffix}.tsv", "- metaphlan estimated taxonomic relative abundances\n\n"))

    # processing info
    output.write("    {:<75} {:>0}".format("- " + str(processing_zip_file), "- zip archive holding info related to processing\n"))
    output.write("        {:<71} {:>0}".format("- unique-sample-IDs.txt", "- single-column file of unique sample identifiers\n"))
    output.write("        {:<71} {:>0}".format("- Snakefile", "- Snakemake workflow file\n"))
    output.write("        {:<71} {:>0}".format("- config.yaml", "- configuration file for workflow\n"))
    output.write("        {:<71} {:>0}".format("- envs/", "- conda environments for workflow\n"))
    output.write("        {:<71} {:>0}".format("- scripts/", "- scripts used by workflow\n"))
    output.write("        {:<71} {:>0}".format("- logs/", "- log files of specific commands run\n"))

    output.write("\n")


def write_methylseq_body(output):

    # this file
    output.write("    {:<41} {:>0}".format("- " + str(output_file), "- this file\n\n"))

    # fastqc info
    output.write("    {:<41} {:>0}".format("- " + str(fastqc_dir), "- multiQC summary reports of FastQC runs\n\n"))

    # quality-filtered reads
    output.write("    {:<41} {:>0}".format("- " + str(filtered_reads_dir), "- quality-filtered and trimmed fastq files\n\n"))

    # reference files
    output.write("    {:<41} {:>0}".format("- " + str(ref_files_dir), "- reference genome files (including bed, gtf, and fasta)\n\n"))

    # bismark index files
    output.write("    {:<41} {:>0}".format("- " + str(bismark_index_zip), "- zip archive of bismark index files\n\n"))

    # bismark alignment files
    output.write("    {:<41} {:>0}".format("- " + str(bismark_alignments_dir), "- bismark alignment files, logs, and qualimap reports\n\n"))

    # bismark methylation calls
    output.write("    {:<41} {:>0}".format("- " + str(bismark_meth_calls_dir), "- methylation-call files and logs from bismark_methylation_extractor\n\n"))

    # bismark summary files
    output.write("    {:<41} {:>0}".format("- " + str(bismark_summary_dir), "- bismark summary reports and html files\n\n"))

    # methylkit outputs
    output.write("    {:<41} {:>0}".format("- " + str(methylkit_outputs_dir), "- MethylKit differential methylation outputs, and tables of genome-wide methylation percentages per sample\n\n"))

    # processing info
    output.write("    {:<41} {:>0}".format("- " + str(processing_zip_file), "- zip archive holding info related to processing (workflow files and metadata)\n"))

    output.write("\n")

### variable setup ###

# universal settings
output_prefix = str(args.output_prefix)
fastqc_dir = "FastQC_Outputs/"
filtered_reads_dir = "Filtered_Sequence_Data/"
processing_zip_file = output_prefix + "processing_info.zip"

output_file = output_prefix + str(args.output)

if args.assay == "Amplicon":

    trimmed_reads_dir = "Trimmed_Sequence_Data/"
    final_outputs_dir = "Final_Outputs/"

    if args.protocol_ID == "":

        args.protocol_ID = latest_amplicon_DPPD

elif args.assay == "Metagenomics":

    assay_suffix = "GLmetagenomics"

    assembly_based_dir = "Assembly-based_Processing/"
    assemblies_dir = "assemblies/"
    genes_dir = "predicted-genes/"
    annotations_and_tax_dir = "annotations-and-taxonomy/"
    mapping_dir = "read-mapping/"
    combined_output_dir = "combined-outputs/"
    bins_dir = "bins/"
    MAGs_dir = "MAGs/"
    read_based_dir = "Read-based_Processing/"

    if args.protocol_ID == "":

        args.protocol_ID = latest_metagenomics_DPPD

elif args.assay == "MethylSeq":
    
    ref_files_dir = "Reference_Genome_Files/"
    bismark_index_zip = "Bismark_Index.zip"
    bismark_alignments_dir = "Bismark_Alignments/"
    bismark_meth_calls_dir = "Methylation_Call_Data/"
    bismark_summary_dir = "Bismark_Summary/"
    methylkit_outputs_dir = "Differential_Methylation_Analysis_Data/"

    if args.protocol_ID == "":

        args.protocol_ID = latest_methylseq_DPPD


if __name__ == "__main__":
    main()
