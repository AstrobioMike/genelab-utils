#!/usr/bin/env python

"""
This is a program for generating the table needed by curation for a GeneLab metagenomics raw dataset.
"""

import os
import sys
import argparse
import textwrap
import pandas as pd
import tarfile
import zipfile
import glob

parser = argparse.ArgumentParser(description="This program generates the table needed by Curation for GeneLab metagenomics \
                                             raw datasets.\
                                             Hard-coded variables that may need to be changed are at the top \
                                             of the script. It is expected to be run after the remove-human-reads workflow and \
                                             takes off from the \"Human-read-removal-summary.tsv\" file produced by it. \
                                             This does not currently account for any host-removal steps, so those would need to \
                                             be added manually currently.")

required = parser.add_argument_group('required arguments')

required.add_argument("-g", "--GLDS-ID", help='GLDS ID (e.g. "GLDS-276")', action="store", required = True)
required.add_argument("-i", "--human-read-removal-summary-file", help='The human-read-removal-summary file produced by the remove-human-reads workflow', action="store", required = True)
parser.add_argument("--additional-prefix", help="Add any expected additional filename prefix that was added to the files that describe multiple samples (default: \"\")", default = "", action="store")
parser.add_argument("--include-qc-files", help="Add this flag if this is a GeneLab-generated dataset, and therefore also has QC files", action="store_true")


if len(sys.argv)==1:
    parser.print_help(sys.stderr)
    sys.exit(0)

args = parser.parse_args()

additional_prefix = str(args.additional_prefix)

### hard-coded stuff we might want to change ###
file_prefix = args.GLDS_ID + "_metagenomics_"

raw_R1_suffix = "_R1_HRremoved_raw.fastq.gz"
raw_R2_suffix = "_R2_HRremoved_raw.fastq.gz"
multiqc_data = "raw_multiqc_data.zip"
multiqc_html = "raw_multiqc_report.html"

################################################################################

def main():

    check_for_file_and_contents(args.human_read_removal_summary_file)

    df = read_in_summary_tab(args.human_read_removal_summary_file)

    gen_and_write_out_filenames_table(df)


################################################################################


# setting some colors
tty_colors = {
    'green' : '\033[0;32m%s\033[0m',
    'yellow' : '\033[0;33m%s\033[0m',
    'red' : '\033[0;31m%s\033[0m'
}


### functions ###

def color_text(text, color='green'):
    if sys.stdout.isatty():
        return tty_colors[color] % text
    else:
        return text


def wprint(text):
    """ print wrapper """

    print(textwrap.fill(text, width=80, initial_indent="  ",
          subsequent_indent="  ", break_on_hyphens=False))


def report_failure(message, color = "yellow"):
    print("")
    wprint(color_text(message, color))
    print("\nJIRA-table generation failed.\n")
    sys.exit(1)


def check_for_file_and_contents(file_path):
    """ used by check_fastq_files function """

    if not os.path.exists(file_path):
        report_failure("The expected file '" + str(file_path) + "' does not exist.")
    if not os.path.getsize(file_path) > 0:
        report_failure("The file '" + str(file_path) + "' is empty.")


def read_in_summary_tab(file_path):

    df = pd.read_csv(file_path, sep = "\t", usecols = [0,2,3])

    return(df)


def gen_and_write_out_filenames_table(in_tab):

    header_colnames = ["Sample Name", "Parameter Value[Read Depth]", "Unit", "Term Source REF", "Term Accession Number",
                       "Parameter Value[Human Reads Removed]", "Unit", "Term Source REF", "Term Accession Number",
                       "Parameter Value[Read Depth]", "Unit", "Term Source REF", "Term Accession Number",
                       "Assay Name", "Raw Data File", "Parameter Value[Multiqc File Names]"]

    # entries that don't change per sample
    read_depth_unit = "read"
    read_depth_term_source = "SO"
    read_depth_term_acc = "http://purl.obolibrary.org/obo/SO_0000150"
    reads_removed_unit = "percent"
    reads_removed_term_source = "UO"
    reads_removed_term_acc = "http://purl.obolibrary.org/obo/UO_0000187"
    assay_name = "metagenomics"
    multiqc_file_names = str(file_prefix) + str(additional_prefix) + str(multiqc_data) + ", " + str(file_prefix) + str(additional_prefix) + str(multiqc_html)

    # making output table
    building_df = pd.DataFrame()

    building_df["Sample Name"] = in_tab["Sample_ID"].tolist()
    
    building_df["Parameter Value[Read Depth]"] = in_tab["Total_fragments_after"].tolist()
    building_df["Unit"] = read_depth_unit
    building_df["Term Source REF"] = read_depth_term_source
    building_df["Term Accession Number"]  = read_depth_term_acc

    building_df["Parameter Value[Human Reads Removed]"] = in_tab["Percent_human_reads_removed"].tolist()
    building_df["new Unit"] = reads_removed_unit
    building_df["new Term Source REF"] = reads_removed_term_source
    building_df["new Term Accession Number"] = reads_removed_term_acc
    
    building_df = building_df.rename(columns = {"new Unit": "Unit", "new Term Source REF": "Term Source REF","new Term Accession Number": "Term Accession Number"})

    building_df["Assay Name"] = assay_name
    
    # building raw file column
    raw_data_file_col = []
    for sample in in_tab["Sample_ID"].tolist():

        to_add = str(file_prefix) + str(sample) + str(raw_R1_suffix) + ", " + str(file_prefix) + str(sample) + str(raw_R2_suffix)
        
        raw_data_file_col.append(to_add)

    building_df["Raw Data File"] = raw_data_file_col

    if args.include_qc_files:
        building_df["Parameter Value[Multiqc File Names]"] = multiqc_file_names

    if additional_prefix != "":
        building_df.to_csv(str(args.GLDS_ID) + "_" + additional_prefix + "Human-read-removed-file-associations.tsv", sep = "\t", index = False)
    else:
        building_df.to_csv(str(args.GLDS_ID) + "-Human-read-removed-file-associations.tsv", sep = "\t", index = False)

if __name__ == "__main__":
    main()

