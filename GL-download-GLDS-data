#!/usr/bin/env python

"""
This is a program for downloading GLDS data files.
"""

import os
import sys
import argparse
import textwrap
import pandas as pd
from time import sleep
import subprocess
from json import loads
from urllib.request import urlopen

parser = argparse.ArgumentParser(description = "This is a program for downloading GLDS data files. For version info, run \
                                                `GL-version`.")

required = parser.add_argument_group('required arguments')

required.add_argument("-g", "--GLDS-ID", help='GLDS ID (e.g. "GLDS-276")', action="store", required = True, type = str)

required.add_argument("-p", "--pattern", help = "If we do not want to download all files (which we often won't), we can specify \
                      a pattern here to subset the total files. For example, if we know we want to download just the fastq.gz \
                      files, we can say '-p fastq.gz'. We can also provide multiple patterns as a comma-separated list. For example, \
                      If we want to download the fastq.gz files that also have 'NxtaFlex', 'metagenomics', and 'raw' in their filenames, we can provide \
                      '-p fastq.gz,NxtaFlex,metagenomics,raw'. Looking through the table produced by the `GL-get-GLDS-files-info` program \
                      can help figure this out if needed. (Note that this is case-sensitive.)", action = "store", type = str)

parser.add_argument("-j", "--jobs", help = "Number of downloads to run in parallel (default: 10)", default = 10, action = "store", type = int)

parser.add_argument("-P", "--print-only", help = "Just print out the files that would be downloaded, rather than downloading them \
                                                  (useful to check we are getting what we want first)", action = "store_true")

parser.add_argument("-f", "--force", help = "Don't ask for confirmation to begin download (helpful if wanting to \
                                                  run non-interactively)", action = "store_true")

parser.add_argument("--just-get-file-info-table", help = "Just download a table of all available files and their urls \
                                                          (doesn't incorporate pattern searching)", action = "store_true") 


if len(sys.argv)==1:
    parser.print_help(sys.stderr)
    sys.exit(0)

args = parser.parse_args()

download_commands_file = str(args.GLDS_ID) + "-wanted-file-download-commands.sh"
not_downloaded_files_file = "files-not-downloaded.txt"

GLDS_file_json_url = "https://genelab-data.ndc.nasa.gov/genelab/data/glds/files/" + str(args.GLDS_ID).removeprefix("GLDS-")

base_file_url_prefix = "https://genelab-data.ndc.nasa.gov"

GLDS_file_info_output_tab = args.GLDS_ID + "-file-info.tsv"

################################################################################

def main():

    # making sure input fits format
    if not args.GLDS_ID.startswith("GLDS-"):

        report_message("The input --GLDS-ID argument needs to be in the format of 'GLDS-' followed by the appropriate GLDS number.")
        print("")
        exit(1)

    # getting GLDS file-info into table
    report_message("Retrieving " + args.GLDS_ID + " file data from:")
    print("    " + GLDS_file_json_url + "\n")
    
    gen_files_table(GLDS_file_json_url)

    # exiting if user just wants file-info table
    if args.just_get_file_info_table:
        exit()

    # reading in file-info table
    in_tab = pd.read_csv(GLDS_file_info_output_tab, sep = "\t")
    
    # number of total files
    num_total_files = len(in_tab.index)
    
    # list of all files
    all_files = in_tab.filename.tolist()

    report_message(f"The downloaded table holds a total of {num_total_files} files.")
    print("")
    sleep(1)

    if args.pattern:

        # splitting if any commas
        if "," in args.pattern:

            patterns = args.pattern.split(",")

        else:

            patterns = [args.pattern]

        # starting empty list of target files that hold the searched patterns
        target_files = []

        for file in all_files:

            if all(pattern in file for pattern in patterns):

                    target_files.append(file)

        # getting rid of any duplicates
        target_files = set(target_files)
        target_files = list(target_files)

        # number of files after filtering
        num_files_to_download = len(target_files)
        
        if num_files_to_download == 0:

            report_message(f"No files were found matching the specified pattern(s) :(")
            report_message(f"Maybe look into the '{GLDS_file_info_output_tab}' file to see what's there.")
            report_message(f"(Also note that the pattern-matching done here is case-sensitive.)")
            print("")
            exit(0)

        report_message(f"{num_files_to_download} file(s) found matching the provided pattern(s).")
        print("")
        sleep(1)

    else:
        num_files_to_download = num_total_files
        target_files = all_files

    if args.print_only:

        report_message(f"As requested, here are the {num_files_to_download} files that would be downloaded by this command if run without the '--print-only' flag:")
        print()
        sleep(2.5)

        for filename in target_files:
            print(f"    {filename}")
            sleep(0.01)

        print("")
        exit(0)

    if not args.force:

        report_message(f"If you'd just like to see a list of the files that would be downloaded, here is your chance to exit and rerun the command with the '--print-only' flag...")
        sleep(1)
        print("")

        print(f"    Enter 'y' if you'd like to begin downloading these {num_files_to_download} files,")
        response = input("    enter any other key to exit without downloading: ")

        if response != "y":

            report_message(f"Exiting without downloading :)")
            print("")
            exit(0)

        else:

            print("")

    # building download script based on curl
    beginning_of_command = "curl -L -s -o"

    with open(download_commands_file, "w") as download_script:

        for file in target_files:

            target_url = in_tab.loc[in_tab['filename'] == file, 'url'].iloc[0]

            download_script.write(f"{beginning_of_command} {file} '{target_url}'\n")

    report_message(f"Beginning download of the {num_files_to_download} file(s)...")
    print("")

    dl_command = f"parallel --xapply -j {args.jobs} < {download_commands_file}"

    subprocess.run(dl_command, shell = True)
    
    # checking expected files were downloaded
    cwd_files = os.listdir(".")

    missing_files = []

    for file in target_files:

        if file not in cwd_files:

            missing_files.append(file)

    num_missing = len(missing_files)

    if num_missing > 0:

        with open(not_downloaded_files_file, "w") as out_file:
            for file in missing_files:
                out_file.write(f"{file}\n")

        report_message(f"Some files ({num_missing}) weren't successfully downloaded for some reason. They have been written to:")
        print(f"    {not_downloaded_files_file}\n")

    else:

        report_message(f"All {num_files_to_download} files have been downloaded :)", "green")
        print("")

    report_message(f"The download commands executed were written to:")
    print(f"    {download_commands_file}\n")


################################################################################

# setting some colors
tty_colors = {
    'green' : '\033[0;32m%s\033[0m',
    'yellow' : '\033[0;33m%s\033[0m',
    'red' : '\033[0;31m%s\033[0m'
}


### functions ###
def color_text(text, color='green'):
    if sys.stdout.isatty():
        return tty_colors[color] % text
    else:
        return text


def wprint(text):
    """ print wrapper """

    print(textwrap.fill(text, width=80, initial_indent="  ",
          subsequent_indent="  ", break_on_hyphens=False))


def report_failure(message, color = "yellow"):
    print("")
    wprint(color_text(message, color))
    print("\nData file info download failed.\n")
    sys.exit(1)


def report_message(message, color = "yellow"):
    print("")
    wprint(color_text(message, color))


def gen_files_table(files_info_url):

    """
    This function access the files info json from https://genelab-data.ndc.nasa.gov/genelab/data/glds/files/<GLDS_ID>
    and creates a table with filenames and links
    """

    # reading fileslisting json
    with urlopen(files_info_url) as json:

        files_json = loads(json.read().decode())

    files_dict = files_json["studies"][args.GLDS_ID]["study_files"]

    # writing out table with filenames and their urls

    with open(GLDS_file_info_output_tab, "w") as out_file:

        # starting header
        out_file.write("filename\turl\n")

        for entry in files_dict:

            filename = entry["file_name"]
            
            file_url = os.path.join(base_file_url_prefix, entry["remote_url"].lstrip("/"))

            out_file.write(f"{filename}\t{file_url}\n")

    # writing out file-info table
    report_message("A table with available filenames and urls has been written to:")
    print("    " + GLDS_file_info_output_tab + "\n")
    sleep(1)



if __name__ == "__main__":
    main()
